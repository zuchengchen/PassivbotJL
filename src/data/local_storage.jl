# src/data/local_storage.jl

"""
æœ¬åœ°æ•°æ®å­˜å‚¨ç®¡ç†å™¨

åŠŸèƒ½ï¼š
- æŒ‰æ—¥æœŸå­˜å‚¨ aggTrades æ•°æ®
- è‡ªåŠ¨æ£€æŸ¥æœ¬åœ°æ˜¯å¦å·²æœ‰æ•°æ®
- æ”¯æŒå¢é‡ä¸‹è½½
- æ”¯æŒ CSV å’Œ Parquet æ ¼å¼
- æ•°æ®å®Œæ•´æ€§éªŒè¯
- DateTime è‡ªåŠ¨è½¬æ¢ï¼ˆParquet å…¼å®¹æ€§ï¼‰
- ç±»å‹ä¼˜åŒ–ï¼ˆç§»é™¤ Union{Missing, T}ï¼‰
- å­—ç¬¦ä¸²ç±»å‹æ ‡å‡†åŒ–ï¼ˆInlineString â†’ Stringï¼‰
"""

using Dates
using DataFrames
using CSV
using Logging
using JSON3
using Parquet

# ============================================================================
# é…ç½®
# ============================================================================

const LOCAL_DATA_DIR = "data/aggtrades"

# æ•°æ®å­˜å‚¨æ ¼å¼
@enum StorageFormat begin
    CSV_FORMAT       # CSV æ ¼å¼ï¼ˆæ˜“è¯»ã€é€šç”¨ï¼‰
    PARQUET_FORMAT   # Parquet æ ¼å¼ï¼ˆæ›´å°ã€æ›´å¿«ï¼‰
end

# é»˜è®¤ä½¿ç”¨ Parquetï¼ˆæ›´é«˜æ•ˆï¼‰
const DEFAULT_FORMAT = PARQUET_FORMAT

# å…ƒæ•°æ®æ–‡ä»¶ï¼ˆè®°å½•æ¯ä¸ªæ–‡ä»¶çš„ä¿¡æ¯ï¼‰
const METADATA_FILE = "metadata.json"

# ============================================================================
# ç±»å‹æ ‡å‡†åŒ–
# ============================================================================

"""
    normalize_dataframe_types(df::DataFrame)::DataFrame

æ ‡å‡†åŒ– DataFrame çš„æ•°æ®ç±»å‹

å¤„ç†ï¼š
- String/Int64 timestamp â†’ DateTime
- InlineString (String7ç­‰) â†’ String
- æ¸…ç† Union{Missing, T}
"""
function normalize_dataframe_types(df::DataFrame)::DataFrame
    df_copy = copy(df)
    
    # å¤„ç† timestamp åˆ—
    if hasproperty(df_copy, :timestamp)
        ts = df_copy.timestamp
        ts_type = eltype(ts)
        
        # å·²ç»æ˜¯ DateTimeï¼Œè·³è¿‡
        if ts_type == DateTime
            # ä¸éœ€è¦å¤„ç†
        # å­—ç¬¦ä¸²ç±»å‹
        elseif ts_type <: AbstractString
            df_copy.timestamp = DateTime.(ts)
        # æ•´æ•°ç±»å‹ï¼ˆUnix æ—¶é—´æˆ³ï¼Œæ¯«ç§’ï¼‰
        elseif ts_type <: Integer
            df_copy.timestamp = unix2datetime.(ts ./ 1000)
        # Union ç±»å‹
        elseif ts_type isa Union
            base_type = Base.nonmissingtype(ts_type)
            if base_type <: AbstractString
                df_copy.timestamp = map(x -> ismissing(x) ? DateTime(0) : DateTime(x), ts)
            elseif base_type <: Integer
                df_copy.timestamp = map(x -> ismissing(x) ? DateTime(0) : unix2datetime(x / 1000), ts)
            end
        end
    end
    
    # å¤„ç†å­—ç¬¦ä¸²åˆ—ï¼ˆè½¬æ¢ InlineString ä¸º Stringï¼‰
    for col in names(df_copy)
        col_data = df_copy[:, col]
        col_type = eltype(col_data)
        
        if col_type <: AbstractString && col_type != String
            df_copy[:, col] = String.(col_data)
        elseif col_type isa Union
            base_type = Base.nonmissingtype(col_type)
            if base_type <: AbstractString && base_type != String
                df_copy[:, col] = map(x -> ismissing(x) ? missing : String(x), col_data)
            end
        end
    end
    
    return df_copy
end

# ============================================================================
# DateTime è½¬æ¢è¾…åŠ©å‡½æ•°ï¼ˆParquet å…¼å®¹æ€§ï¼‰
# ============================================================================

"""
    prepare_for_parquet(df::DataFrame)::DataFrame

å‡†å¤‡ DataFrame ç”¨äº Parquet ä¿å­˜
"""
function prepare_for_parquet(df::DataFrame)::DataFrame
    # æ„å»ºæ–°åˆ—çš„å­—å…¸
    cols = Dict{Symbol, Any}()
    
    for col_name in names(df)
        col_sym = Symbol(col_name)
        col_data = df[:, col_name]
        col_type = eltype(col_data)
        
        # DateTime â†’ Int64
        if col_type == DateTime
            cols[col_sym] = round.(Int64, datetime2unix.(col_data) .* 1000)
        # InlineString â†’ String
        elseif col_type <: AbstractString && col_type != String
            cols[col_sym] = String.(col_data)
        # Union{Missing, DateTime}
        elseif col_type isa Union && Base.nonmissingtype(col_type) == DateTime
            cols[col_sym] = map(x -> ismissing(x) ? missing : round(Int64, datetime2unix(x) * 1000), col_data)
        # Union{Missing, InlineString}
        elseif col_type isa Union && Base.nonmissingtype(col_type) <: AbstractString && Base.nonmissingtype(col_type) != String
            cols[col_sym] = map(x -> ismissing(x) ? missing : String(x), col_data)
        # å…¶ä»–ç±»å‹ä¿æŒä¸å˜
        else
            cols[col_sym] = col_data
        end
    end
    
    return DataFrame(cols)
end

"""
    restore_from_parquet(df::DataFrame)::DataFrame

ä» Parquet æ¢å¤ DataFrameï¼ˆè½¬æ¢ Int64 å› DateTimeï¼Œæ¸…ç†ç±»å‹ï¼‰
"""
function restore_from_parquet(df::DataFrame)::DataFrame
    df_copy = copy(df)
    
    # 1. è½¬æ¢æ—¶é—´æˆ³å› DateTime
    if hasproperty(df_copy, :timestamp)
        timestamps = df_copy.timestamp
        
        # åˆ›å»º DateTime å‘é‡
        datetime_vec = Vector{DateTime}(undef, length(timestamps))
        
        for i in eachindex(timestamps)
            val = timestamps[i]
            if ismissing(val)
                datetime_vec[i] = DateTime(0)
            elseif val isa Integer
                datetime_vec[i] = unix2datetime(val / 1000)
            elseif val isa DateTime
                datetime_vec[i] = val
            else
                datetime_vec[i] = DateTime(0)
            end
        end
        
        df_copy.timestamp = datetime_vec
    end
    
    # 2. æ¸…ç†å…¶ä»–åˆ—çš„ Union{Missing, T} ç±»å‹
    for col in names(df_copy)
        if col in ("timestamp", :timestamp)
            continue
        end
        
        col_data = df_copy[:, col]
        col_type = eltype(col_data)
        
        # å¦‚æœæ˜¯ Union{Missing, T} ä½†æ²¡æœ‰å®é™… missing å€¼
        if col_type isa Union && Missing <: col_type
            if !any(ismissing, col_data)
                non_missing_type = Base.nonmissingtype(col_type)
                df_copy[:, col] = Vector{non_missing_type}(col_data)
            end
        end
    end
    
    return df_copy
end

# ============================================================================
# è·¯å¾„ç®¡ç†
# ============================================================================

"""
    get_local_data_path(symbol::String, date::Date, market::Symbol, format::StorageFormat)::String

è·å–æœ¬åœ°æ•°æ®æ–‡ä»¶è·¯å¾„
"""
function get_local_data_path(
    symbol::String,
    date::Date,
    market::Symbol,
    format::StorageFormat=DEFAULT_FORMAT
)::String
    
    # æ„å»ºç›®å½•ç»“æ„
    market_dir = joinpath(LOCAL_DATA_DIR, string(market))
    symbol_dir = joinpath(market_dir, symbol)
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    mkpath(symbol_dir)
    
    # æ–‡ä»¶å
    date_str = Dates.format(date, "yyyy-mm-dd")
    extension = format == CSV_FORMAT ? "csv" : "parquet"
    
    return joinpath(symbol_dir, "$date_str.$extension")
end

"""
    get_local_data_dir(symbol::String, market::Symbol)::String

è·å–äº¤æ˜“å¯¹çš„æœ¬åœ°æ•°æ®ç›®å½•
"""
function get_local_data_dir(symbol::String, market::Symbol)::String
    market_dir = joinpath(LOCAL_DATA_DIR, string(market))
    symbol_dir = joinpath(market_dir, symbol)
    return symbol_dir
end

"""
    get_metadata_path(symbol::String, market::Symbol)::String

è·å–å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„
"""
function get_metadata_path(symbol::String, market::Symbol)::String
    symbol_dir = get_local_data_dir(symbol, market)
    mkpath(symbol_dir)
    return joinpath(symbol_dir, METADATA_FILE)
end

# ============================================================================
# å…ƒæ•°æ®ç®¡ç†
# ============================================================================

"""
    save_metadata(symbol::String, date::Date, market::Symbol, row_count::Int, file_size::Int)

ä¿å­˜æ–‡ä»¶å…ƒæ•°æ®
"""
function save_metadata(
    symbol::String,
    date::Date,
    market::Symbol,
    row_count::Int,
    file_size::Int
)
    
    metadata_path = get_metadata_path(symbol, market)
    
    # è¯»å–ç°æœ‰å…ƒæ•°æ®ï¼ˆè½¬æ¢ä¸ºå¯å˜çš„ Dictï¼‰
    metadata = if isfile(metadata_path)
        try
            # âœ… ä¿®å¤ï¼šé€’å½’è½¬æ¢æ‰€æœ‰é”®ä¸º String
            json_data = JSON3.read(read(metadata_path, String))
            convert_keys_to_string(json_data)
        catch e
            @warn "Failed to read existing metadata, creating new" error=e
            Dict{String, Any}()
        end
    else
        Dict{String, Any}()
    end
    
    # æ›´æ–°å…ƒæ•°æ®
    date_str = Dates.format(date, "yyyy-mm-dd")
    metadata[date_str] = Dict{String, Any}(
        "rows" => row_count,
        "size" => file_size,
        "updated" => string(now())
    )
    
    # ä¿å­˜
    try
        write(metadata_path, JSON3.write(metadata))
    catch e
        @warn "Failed to save metadata" error=e
    end
end

"""
    convert_keys_to_string(obj)

é€’å½’è½¬æ¢æ‰€æœ‰é”®ä¸º String
"""
function convert_keys_to_string(obj)
    if obj isa AbstractDict
        result = Dict{String, Any}()
        for (k, v) in obj
            key_str = k isa Symbol ? String(k) : string(k)
            result[key_str] = convert_keys_to_string(v)
        end
        return result
    elseif obj isa AbstractArray
        return [convert_keys_to_string(x) for x in obj]
    else
        return obj
    end
end

"""
    load_metadata(symbol::String, market::Symbol)::Dict

åŠ è½½å…ƒæ•°æ®
"""
function load_metadata(symbol::String, market::Symbol)::Dict
    
    metadata_path = get_metadata_path(symbol, market)
    
    if !isfile(metadata_path)
        return Dict{String, Any}()
    end
    
    try
        # âœ… ä¿®å¤ï¼šè½¬æ¢ä¸ºå¯å˜ Dict
        json_data = JSON3.read(read(metadata_path, String))
        return Dict{String, Any}(json_data)
    catch e
        @warn "Failed to load metadata" error=e
        return Dict{String, Any}()
    end
end

# ============================================================================
# æ•°æ®æ£€æŸ¥
# ============================================================================

"""
    has_local_data(symbol::String, date::Date, market::Symbol)::Bool

æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰æŒ‡å®šæ—¥æœŸçš„æ•°æ®ï¼ˆè‡ªåŠ¨æ£€æµ‹æ ¼å¼ï¼‰
"""
function has_local_data(
    symbol::String,
    date::Date,
    market::Symbol
)::Bool
    
    # æ£€æŸ¥ä¸¤ç§æ ¼å¼
    for format in [PARQUET_FORMAT, CSV_FORMAT]
        path = get_local_data_path(symbol, date, market, format)
        
        if !isfile(path)
            continue
        end
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å®Œæ•´ï¼ˆå¤§å° > 0ï¼‰
        file_size = stat(path).size
        if file_size == 0
            @warn "Local data file is empty" path=path
            continue
        end
        
        return true
    end
    
    return false
end

"""
    get_missing_dates(symbol::String, start_date::Date, end_date::Date, market::Symbol)::Vector{Date}

è·å–ç¼ºå¤±çš„æ—¥æœŸåˆ—è¡¨
"""
function get_missing_dates(
    symbol::String,
    start_date::Date,
    end_date::Date,
    market::Symbol
)::Vector{Date}
    
    missing_dates = Date[]
    
    current_date = start_date
    while current_date <= end_date
        if !has_local_data(symbol, current_date, market)
            push!(missing_dates, current_date)
        end
        current_date += Day(1)
    end
    
    return missing_dates
end

"""
    get_available_dates(symbol::String, market::Symbol)::Vector{Date}

è·å–æœ¬åœ°å·²æœ‰çš„æ‰€æœ‰æ—¥æœŸ
"""
function get_available_dates(symbol::String, market::Symbol)::Vector{Date}
    
    symbol_dir = get_local_data_dir(symbol, market)
    
    if !isdir(symbol_dir)
        return Date[]
    end
    
    dates = Date[]
    
    for file in readdir(symbol_dir)
        # åŒ¹é… yyyy-mm-dd.csv æˆ– yyyy-mm-dd.parquet
        m = match(r"(\d{4}-\d{2}-\d{2})\.(csv|parquet)$", file)
        if !isnothing(m)
            try
                date = Date(m.captures[1], "yyyy-mm-dd")
                push!(dates, date)
            catch
                @warn "Invalid date in filename" file=file
            end
        end
    end
    
    return sort(unique(dates))
end

"""
    get_date_coverage(symbol::String, start_date::Date, end_date::Date, market::Symbol)::Float64

è·å–æ—¥æœŸèŒƒå›´çš„è¦†ç›–ç‡ï¼ˆ0.0-1.0ï¼‰
"""
function get_date_coverage(
    symbol::String,
    start_date::Date,
    end_date::Date,
    market::Symbol
)::Float64
    
    total_days = Dates.value(end_date - start_date) + 1
    
    if total_days <= 0
        return 0.0
    end
    
    available_count = 0
    current_date = start_date
    
    while current_date <= end_date
        if has_local_data(symbol, current_date, market)
            available_count += 1
        end
        current_date += Day(1)
    end
    
    return available_count / total_days
end

# ============================================================================
# æ•°æ®è¯»å†™
# ============================================================================

"""
    save_local_data(df::DataFrame, symbol::String, date::Date, market::Symbol, format::StorageFormat)

ä¿å­˜æ•°æ®åˆ°æœ¬åœ°
"""
function save_local_data(
    df::DataFrame,
    symbol::String,
    date::Date,
    market::Symbol,
    format::StorageFormat=DEFAULT_FORMAT
)
    
    if nrow(df) == 0
        @warn "Empty DataFrame, not saving" symbol=symbol date=date
        return
    end
    
    path = get_local_data_path(symbol, date, market, format)
    
    try
        if format == CSV_FORMAT
            CSV.write(path, df)
        else
            # Parquet æ ¼å¼ï¼šéœ€è¦è½¬æ¢ DateTime å’Œæ¸…ç†ç±»å‹
            df_parquet = prepare_for_parquet(df)
            write_parquet(path, df_parquet)
        end
        
        file_size = stat(path).size
        file_size_mb = file_size / (1024 * 1024)
        
        # ä¿å­˜å…ƒæ•°æ®
        save_metadata(symbol, date, market, nrow(df), file_size)
        
        @info "Saved local data" symbol=symbol date=date rows=nrow(df) size_mb=round(file_size_mb, digits=2) format=format
        
    catch e
        @error "Failed to save local data" symbol=symbol date=date error=e
        
        # å¦‚æœæ˜¯ Parquet å¤±è´¥ï¼Œå°è¯•é™çº§åˆ° CSV
        if format == PARQUET_FORMAT
            @warn "Parquet save failed, falling back to CSV" symbol=symbol date=date
            try
                csv_path = get_local_data_path(symbol, date, market, CSV_FORMAT)
                CSV.write(csv_path, df)
                
                file_size = stat(csv_path).size
                save_metadata(symbol, date, market, nrow(df), file_size)
                
                @info "Saved as CSV instead" path=csv_path
            catch e2
                @error "CSV fallback also failed" error=e2
            end
        end
    end
end

"""
    load_local_data(symbol::String, date::Date, market::Symbol)::DataFrame

ä»æœ¬åœ°åŠ è½½æ•°æ®ï¼ˆè‡ªåŠ¨æ£€æµ‹æ ¼å¼ï¼‰
"""
function load_local_data(
    symbol::String,
    date::Date,
    market::Symbol
)::DataFrame
    
    # ä¼˜å…ˆå°è¯• Parquetï¼Œå…¶æ¬¡ CSV
    for format in [PARQUET_FORMAT, CSV_FORMAT]
        path = get_local_data_path(symbol, date, market, format)
        
        if !isfile(path)
            continue
        end
        
        try
            df = if format == CSV_FORMAT
                df_csv = CSV.read(path, DataFrame)
                
                # æ ‡å‡†åŒ–ç±»å‹
                normalize_dataframe_types(df_csv)
            else
                # Parquet æ ¼å¼ï¼šè¯»å–å¹¶æ¢å¤ DateTime
                df_parquet = DataFrame(read_parquet(path))
                restore_from_parquet(df_parquet)
            end
            
            @debug "Loaded local data" symbol=symbol date=date rows=nrow(df) format=format
            
            return df
            
        catch e
            @error "Failed to load local data" path=path error=e format=format
            continue
        end
    end
    
    @debug "Local data file not found" symbol=symbol date=date
    return DataFrame()
end

"""
    load_local_data_range(symbol::String, start_date::Date, end_date::Date, market::Symbol)::DataFrame

åŠ è½½æ—¥æœŸèŒƒå›´å†…çš„æ‰€æœ‰æœ¬åœ°æ•°æ®
"""
function load_local_data_range(
    symbol::String,
    start_date::Date,
    end_date::Date,
    market::Symbol
)::DataFrame
    
    all_data = DataFrame[]
    loaded_dates = Date[]
    
    current_date = start_date
    while current_date <= end_date
        if has_local_data(symbol, current_date, market)
            df = load_local_data(symbol, current_date, market)
            if nrow(df) > 0
                push!(all_data, df)
                push!(loaded_dates, current_date)
            end
        end
        current_date += Day(1)
    end
    
    if isempty(all_data)
        return DataFrame(
            agg_trade_id = Int64[],
            price = Float64[],
            quantity = Float64[],
            first_trade_id = Int64[],
            last_trade_id = Int64[],
            timestamp = DateTime[],
            is_buyer_maker = Bool[],
            symbol = String[]
        )
    end
    
    # åˆå¹¶å¹¶æ’åº
    result = vcat(all_data...)
    sort!(result, :timestamp)
    unique!(result, :agg_trade_id)
    
    @info "Loaded local data range" symbol=symbol dates=length(loaded_dates) rows=nrow(result)
    
    return result
end

# ============================================================================
# æ•°æ®éªŒè¯
# ============================================================================

"""
    validate_local_data(symbol::String, date::Date, market::Symbol)::Bool

éªŒè¯æœ¬åœ°æ•°æ®çš„å®Œæ•´æ€§
"""
function validate_local_data(
    symbol::String,
    date::Date,
    market::Symbol
)::Bool
    
    if !has_local_data(symbol, date, market)
        return false
    end
    
    try
        df = load_local_data(symbol, date, market)
        
        # æ£€æŸ¥å¿…éœ€çš„åˆ—
        required_cols = [:agg_trade_id, :price, :quantity, :timestamp, :is_buyer_maker]
        for col in required_cols
            if !hasproperty(df, col)
                @warn "Missing required column" symbol=symbol date=date column=col
                return false
            end
        end
        
        # æ£€æŸ¥æ•°æ®é‡ï¼ˆè‡³å°‘åº”è¯¥æœ‰ä¸€äº›æ•°æ®ï¼‰
        if nrow(df) < 100
            @warn "Too few rows" symbol=symbol date=date rows=nrow(df)
            return false
        end
        
        # æ£€æŸ¥æ—¶é—´èŒƒå›´ï¼ˆåº”è¯¥åœ¨æŒ‡å®šæ—¥æœŸå†…ï¼‰
        min_date = Date(minimum(df.timestamp))
        max_date = Date(maximum(df.timestamp))
        
        if min_date != date && max_date != date
            @warn "Date mismatch" symbol=symbol expected=date actual_range=(min_date, max_date)
            return false
        end
        
        return true
        
    catch e
        @warn "Validation failed" symbol=symbol date=date error=e
        return false
    end
end

# ============================================================================
# æ•°æ®ç®¡ç†
# ============================================================================

"""
    clean_local_data(;older_than_days::Int=30, market::Union{Symbol,Nothing}=nothing, dry_run::Bool=false)

æ¸…ç†æ—§çš„æœ¬åœ°æ•°æ®
"""
function clean_local_data(;
    older_than_days::Int=30,
    market::Union{Symbol,Nothing}=nothing,
    dry_run::Bool=false
)
    
    cutoff_date = today() - Day(older_than_days)
    
    markets_to_clean = if isnothing(market)
        [:spot, :futures]
    else
        [market]
    end
    
    total_deleted = 0
    total_freed_mb = 0.0
    files_to_delete = []
    
    for mkt in markets_to_clean
        market_dir = joinpath(LOCAL_DATA_DIR, string(mkt))
        
        if !isdir(market_dir)
            continue
        end
        
        for symbol_name in readdir(market_dir)
            symbol_dir = joinpath(market_dir, symbol_name)
            
            if !isdir(symbol_dir)
                continue
            end
            
            for file in readdir(symbol_dir)
                # è·³è¿‡å…ƒæ•°æ®æ–‡ä»¶
                if file == METADATA_FILE
                    continue
                end
                
                # åŒ¹é…æ—¥æœŸ
                m = match(r"(\d{4}-\d{2}-\d{2})\.(csv|parquet)$", file)
                if !isnothing(m)
                    try
                        file_date = Date(m.captures[1], "yyyy-mm-dd")
                        
                        if file_date < cutoff_date
                            file_path = joinpath(symbol_dir, file)
                            file_size_mb = stat(file_path).size / (1024 * 1024)
                            
                            push!(files_to_delete, (file_path, file_date, file_size_mb))
                            total_deleted += 1
                            total_freed_mb += file_size_mb
                        end
                    catch e
                        @warn "Error processing file" file=file error=e
                    end
                end
            end
        end
    end
    
    if dry_run
        println("\nğŸ” é¢„è§ˆæ¸…ç†æ“ä½œï¼ˆä¸ä¼šå®é™…åˆ é™¤ï¼‰:")
        println("  å°†åˆ é™¤ $total_deleted ä¸ªæ–‡ä»¶")
        println("  å°†é‡Šæ”¾ $(round(total_freed_mb, digits=2)) MB")
        
        if !isempty(files_to_delete)
            println("\n  æ–‡ä»¶åˆ—è¡¨:")
            for (path, date, size_mb) in first(files_to_delete, 10)
                println("    â€¢ $date ($(round(size_mb, digits=2)) MB)")
            end
            
            if length(files_to_delete) > 10
                println("    ... è¿˜æœ‰ $(length(files_to_delete) - 10) ä¸ªæ–‡ä»¶")
            end
        end
    else
        # å®é™…åˆ é™¤
        for (path, date, size_mb) in files_to_delete
            try
                rm(path)
                @debug "Deleted old data" path=path date=date size_mb=size_mb
            catch e
                @warn "Failed to delete file" path=path error=e
            end
        end
        
        @info "Local data cleanup complete" deleted_files=total_deleted freed_mb=round(total_freed_mb, digits=2)
    end
    
    return (deleted=total_deleted, freed_mb=total_freed_mb)
end

"""
    repair_local_data(symbol::String, market::Symbol)

ä¿®å¤æŸåçš„æœ¬åœ°æ•°æ®æ–‡ä»¶
"""
function repair_local_data(symbol::String, market::Symbol)
    
    println("\nğŸ”§ æ£€æŸ¥å¹¶ä¿®å¤æœ¬åœ°æ•°æ®: $symbol ($market)")
    
    dates = get_available_dates(symbol, market)
    
    if isempty(dates)
        println("  æ²¡æœ‰æ‰¾åˆ°æœ¬åœ°æ•°æ®")
        return
    end
    
    corrupted_count = 0
    repaired_count = 0
    
    for date in dates
        if !validate_local_data(symbol, date, market)
            corrupted_count += 1
            println("  âŒ æŸå: $date")
            
            # åˆ é™¤æŸåçš„æ–‡ä»¶ï¼ˆå°è¯•ä¸¤ç§æ ¼å¼ï¼‰
            for format in [PARQUET_FORMAT, CSV_FORMAT]
                path = get_local_data_path(symbol, date, market, format)
                if isfile(path)
                    try
                        rm(path)
                        repaired_count += 1
                        println("    âœ… å·²åˆ é™¤ $(format == CSV_FORMAT ? "CSV" : "Parquet")ï¼Œéœ€è¦é‡æ–°ä¸‹è½½")
                    catch e
                        println("    âŒ åˆ é™¤å¤±è´¥: $e")
                    end
                end
            end
        end
    end
    
    if corrupted_count == 0
        println("  âœ… æ‰€æœ‰æ•°æ®å®Œæ•´")
    else
        println("\n  æ€»è®¡: å‘ç° $corrupted_count ä¸ªæŸåæ–‡ä»¶ï¼Œåˆ é™¤ $repaired_count ä¸ª")
    end
end

# ============================================================================
# ç»Ÿè®¡ä¿¡æ¯
# ============================================================================

"""
    get_local_storage_info(;market::Union{Symbol,Nothing}=nothing, detailed::Bool=false)

è·å–æœ¬åœ°å­˜å‚¨ä¿¡æ¯
"""
function get_local_storage_info(;
    market::Union{Symbol,Nothing}=nothing,
    detailed::Bool=false
)
    
    println("\n" * "="^70)
    println("æœ¬åœ°æ•°æ®å­˜å‚¨ä¿¡æ¯")
    println("="^70)
    
    markets_to_check = if isnothing(market)
        [:spot, :futures]
    else
        [market]
    end
    
    grand_total_files = 0
    grand_total_size_mb = 0.0
    
    for mkt in markets_to_check
        market_dir = joinpath(LOCAL_DATA_DIR, string(mkt))
        
        println("\nğŸ“‚ å¸‚åœº: $mkt")
        println("  è·¯å¾„: $market_dir")
        
        if !isdir(market_dir)
            println("  ï¼ˆæ— æ•°æ®ï¼‰")
            continue
        end
        
        total_files = 0
        total_size_mb = 0.0
        symbol_stats = []
        
        for symbol_name in sort(readdir(market_dir))
            symbol_dir = joinpath(market_dir, symbol_name)
            
            if !isdir(symbol_dir)
                continue
            end
            
            files = filter(f -> f != METADATA_FILE, readdir(symbol_dir))
            symbol_files = length(files)
            symbol_size_mb = sum(stat(joinpath(symbol_dir, f)).size for f in files) / (1024 * 1024)
            
            total_files += symbol_files
            total_size_mb += symbol_size_mb
            
            # è·å–æ—¥æœŸèŒƒå›´
            dates = get_available_dates(symbol_name, mkt)
            date_range = if !isempty(dates)
                "$(dates[1]) åˆ° $(dates[end])"
            else
                "æ— "
            end
            
            # ç»Ÿè®¡æ ¼å¼
            parquet_count = count(f -> endswith(f, ".parquet"), files)
            csv_count = count(f -> endswith(f, ".csv"), files)
            
            push!(symbol_stats, (
                symbol=symbol_name,
                files=symbol_files,
                size_mb=symbol_size_mb,
                date_range=date_range,
                dates=dates,
                parquet_count=parquet_count,
                csv_count=csv_count
            ))
        end
        
        if detailed
            println("\n  äº¤æ˜“å¯¹è¯¦æƒ…:")
            for stat in symbol_stats
                println("    ğŸ“Š $(stat.symbol):")
                println("       æ–‡ä»¶æ•°: $(stat.files) (Parquet: $(stat.parquet_count), CSV: $(stat.csv_count))")
                println("       å¤§å°: $(round(stat.size_mb, digits=2)) MB")
                println("       æ—¥æœŸèŒƒå›´: $(stat.date_range)")
                
                # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                if !isempty(stat.dates)
                    gaps = find_date_gaps(stat.dates)
                    if !isempty(gaps)
                        println("       âš ï¸  ç¼ºå¤±æ—¥æœŸ: $(length(gaps)) ä¸ª")
                    end
                end
            end
        else
            println("\n  äº¤æ˜“å¯¹æ¦‚è§ˆ:")
            for stat in symbol_stats
                format_info = if stat.parquet_count > 0 && stat.csv_count > 0
                    "(æ··åˆ)"
                elseif stat.parquet_count > 0
                    "(Parquet)"
                else
                    "(CSV)"
                end
                println("    ğŸ“Š $(stat.symbol): $(stat.files) å¤©, $(round(stat.size_mb, digits=2)) MB $format_info")
            end
        end
        
        println("\n  å°è®¡: $total_files ä¸ªæ–‡ä»¶, $(round(total_size_mb, digits=2)) MB")
        
        grand_total_files += total_files
        grand_total_size_mb += total_size_mb
    end
    
    println("\n" * "="^70)
    println("æ€»è®¡: $grand_total_files ä¸ªæ–‡ä»¶, $(round(grand_total_size_mb, digits=2)) MB")
    println("="^70)
end

"""
    find_date_gaps(dates::Vector{Date})::Vector{Date}

æ‰¾å‡ºæ—¥æœŸåºåˆ—ä¸­çš„ç¼ºå¤±æ—¥æœŸ
"""
function find_date_gaps(dates::Vector{Date})::Vector{Date}
    
    if length(dates) < 2
        return Date[]
    end
    
    sorted_dates = sort(dates)
    gaps = Date[]
    
    for i in 1:(length(sorted_dates)-1)
        current = sorted_dates[i]
        next = sorted_dates[i+1]
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±çš„æ—¥æœŸ
        expected_next = current + Day(1)
        while expected_next < next
            push!(gaps, expected_next)
            expected_next += Day(1)
        end
    end
    
    return gaps
end

"""
    print_storage_summary()

æ‰“å°å­˜å‚¨æ‘˜è¦ï¼ˆç®€æ´ç‰ˆï¼‰
"""
function print_storage_summary()
    
    if !isdir(LOCAL_DATA_DIR)
        println("ğŸ“¦ æœ¬åœ°å­˜å‚¨: æ— æ•°æ®")
        return
    end
    
    total_size_mb = 0.0
    total_files = 0
    parquet_count = 0
    csv_count = 0
    
    for mkt in [:spot, :futures]
        market_dir = joinpath(LOCAL_DATA_DIR, string(mkt))
        
        if isdir(market_dir)
            for symbol_name in readdir(market_dir)
                symbol_dir = joinpath(market_dir, symbol_name)
                
                if isdir(symbol_dir)
                    files = filter(f -> f != METADATA_FILE, readdir(symbol_dir))
                    total_files += length(files)
                    total_size_mb += sum(stat(joinpath(symbol_dir, f)).size for f in files) / (1024 * 1024)
                    
                    parquet_count += count(f -> endswith(f, ".parquet"), files)
                    csv_count += count(f -> endswith(f, ".csv"), files)
                end
            end
        end
    end
    
    if total_files > 0
        format_info = if parquet_count > 0 && csv_count > 0
            "Parquet: $parquet_count, CSV: $csv_count"
        elseif parquet_count > 0
            "Parquet: $parquet_count"
        else
            "CSV: $csv_count"
        end
        println("ğŸ“¦ æœ¬åœ°å­˜å‚¨: $total_files ä¸ªæ–‡ä»¶, $(round(total_size_mb, digits=2)) MB ($format_info)")
    else
        println("ğŸ“¦ æœ¬åœ°å­˜å‚¨: æ— æ•°æ®")
    end
end

# ============================================================================
# æ ¼å¼è½¬æ¢
# ============================================================================

"""
    convert_to_parquet(symbol::String, market::Symbol)

å°† CSV æ–‡ä»¶è½¬æ¢ä¸º Parquet æ ¼å¼ï¼ˆå®‰å…¨ç‰ˆæœ¬ï¼‰
"""
function convert_to_parquet(symbol::String, market::Symbol)
    
    println("\nğŸ”„ è½¬æ¢ä¸º Parquet æ ¼å¼: $symbol ($market)")
    
    dates = get_available_dates(symbol, market)
    
    if isempty(dates)
        println("  æ²¡æœ‰æ‰¾åˆ°æ•°æ®")
        return
    end
    
    converted_count = 0
    total_saved_mb = 0.0
    
    for date in dates
        csv_path = get_local_data_path(symbol, date, market, CSV_FORMAT)
        parquet_path = get_local_data_path(symbol, date, market, PARQUET_FORMAT)
        
        # åªè½¬æ¢ CSV æ–‡ä»¶
        if isfile(csv_path) && !isfile(parquet_path)
            try
                # è¯»å– CSV
                df_raw = CSV.read(csv_path, DataFrame)
                
                # åˆ›å»ºæ–°çš„ DataFrameï¼Œç¡®ä¿ç±»å‹æ­£ç¡®
                df = DataFrame(
                    agg_trade_id = Vector{Int64}(df_raw.agg_trade_id),
                    price = Vector{Float64}(df_raw.price),
                    quantity = Vector{Float64}(df_raw.quantity),
                    first_trade_id = Vector{Int64}(df_raw.first_trade_id),
                    last_trade_id = Vector{Int64}(df_raw.last_trade_id),
                    timestamp = Vector{DateTime}(df_raw.timestamp),
                    is_buyer_maker = Vector{Bool}(df_raw.is_buyer_maker),
                    symbol = String.(df_raw.symbol)
                )
                
                # å‡†å¤‡å¹¶ä¿å­˜ä¸º Parquet
                df_parquet = prepare_for_parquet(df)
                write_parquet(parquet_path, df_parquet)
                
                # æ›´æ–°å…ƒæ•°æ®
                file_size = stat(parquet_path).size
                save_metadata(symbol, date, market, nrow(df), file_size)
                
                # è®¡ç®—èŠ‚çœçš„ç©ºé—´
                csv_size_mb = stat(csv_path).size / (1024 * 1024)
                parquet_size_mb = file_size / (1024 * 1024)
                saved_mb = csv_size_mb - parquet_size_mb
                
                total_saved_mb += saved_mb
                
                # åˆ é™¤ CSV æ–‡ä»¶
                rm(csv_path)
                
                println("  âœ… $date: $(round(csv_size_mb, digits=2)) MB â†’ $(round(parquet_size_mb, digits=2)) MB (èŠ‚çœ $(round(saved_mb, digits=2)) MB)")
                
                converted_count += 1
                
            catch e
                println("  âŒ $date: è½¬æ¢å¤±è´¥ - $e")
            end
        end
    end
    
    if converted_count == 0
        println("  æ²¡æœ‰éœ€è¦è½¬æ¢çš„æ–‡ä»¶")
    else
        println("\n  æ€»è®¡: è½¬æ¢äº† $converted_count ä¸ªæ–‡ä»¶ï¼ŒèŠ‚çœ $(round(total_saved_mb, digits=2)) MB")
    end
end  # âœ… ç¡®ä¿è¿™ä¸ª end å­˜åœ¨