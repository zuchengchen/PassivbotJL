# src/data/data_manager.jl

"""
æ™ºèƒ½æ•°æ®ç®¡ç†å™¨

ä¼˜å…ˆçº§ç­–ç•¥ï¼š
1. æœ¬åœ° Parquet æ–‡ä»¶ï¼ˆæœ€å¿«ï¼Œæœ€ä¼˜å…ˆï¼‰âœ…
2. æœ¬åœ° CSV æ–‡ä»¶ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
3. Binance Vision å†å²æ•°æ®ï¼ˆå¿«é€Ÿã€å®Œæ•´ï¼‰
4. Binance API å®æ—¶æ•°æ®ï¼ˆæœ€æ–°ã€æœ€æ…¢ï¼‰
"""

using Dates
using DataFrames
using CSV

include("binance_vision.jl")
include("binance_api.jl")
include("local_storage.jl")

# ============================================================================
# é…ç½®
# ============================================================================

# Vision æ•°æ®å¯ç”¨æ€§ï¼šé€šå¸¸æ˜¯3å¤©å‰çš„æ•°æ®
const VISION_DELAY_DAYS = 3

# å›æµ‹æ•°æ®ç¼“å­˜ç›®å½•
const BACKTEST_CACHE_DIR = "data/backtest_cache"

# ============================================================================
# æ—¶é—´èŒƒå›´åˆ†å‰²
# ============================================================================

"""
    split_date_range(start_time::DateTime, end_time::DateTime)

å°†æ—¶é—´èŒƒå›´åˆ†å‰²ä¸º Vision å’Œ API ä¸¤éƒ¨åˆ†
"""
function split_date_range(start_time::DateTime, end_time::DateTime)
    
    # Vision æ•°æ®æˆªæ­¢æ—¥æœŸï¼ˆä»Šå¤© - VISION_DELAY_DAYSï¼‰
    vision_cutoff = today() - Day(VISION_DELAY_DAYS)
    
    # è½¬æ¢ä¸ºæ—¥æœŸ
    start_date = Date(start_time)
    end_date = Date(end_time)
    
    vision_range = nothing
    api_range = nothing
    
    # å®Œå…¨åœ¨ Vision èŒƒå›´å†…
    if end_date <= vision_cutoff
        vision_range = (start_date, end_date)
    
    # å®Œå…¨åœ¨ API èŒƒå›´å†…
    elseif start_date > vision_cutoff
        api_range = (start_time, end_time)
    
    # è·¨è¶Šä¸¤ä¸ªèŒƒå›´
    else
        vision_range = (start_date, vision_cutoff)
        
        # æ­£ç¡®æ„é€  DateTime
        api_start_date = vision_cutoff + Day(1)
        api_range = (DateTime(api_start_date), end_time)
    end
    
    return (vision_range, api_range)
end

# ============================================================================
# æœ¬åœ°æ•°æ®æ£€æŸ¥ï¼ˆå¢å¼ºç‰ˆï¼‰
# ============================================================================

"""
    check_local_data_with_format(symbol::String, date::Date, market::Symbol)::Tuple{Bool, Union{StorageFormat, Nothing}}

æ£€æŸ¥æœ¬åœ°æ•°æ®å¹¶è¿”å›æ ¼å¼

è¿”å›ï¼š
- (has_data::Bool, format::Union{StorageFormat, Nothing})
"""
function check_local_data_with_format(
    symbol::String, 
    date::Date, 
    market::Symbol
)::Tuple{Bool, Union{StorageFormat, Nothing}}
    
    # âœ… ä¼˜å…ˆæ£€æŸ¥ Parquet
    parquet_path = get_local_data_path(symbol, date, market, PARQUET_FORMAT)
    if isfile(parquet_path) && stat(parquet_path).size > 0
        return (true, PARQUET_FORMAT)
    end
    
    # å…¶æ¬¡æ£€æŸ¥ CSV
    csv_path = get_local_data_path(symbol, date, market, CSV_FORMAT)
    if isfile(csv_path) && stat(csv_path).size > 0
        return (true, CSV_FORMAT)
    end
    
    return (false, nothing)
end

"""
    get_local_coverage_detailed(symbol::String, start_date::Date, end_date::Date, market::Symbol)

è·å–æœ¬åœ°æ•°æ®è¯¦ç»†è¦†ç›–æƒ…å†µ

è¿”å›ï¼š
- (parquet_dates, csv_dates, missing_dates)
"""
function get_local_coverage_detailed(
    symbol::String,
    start_date::Date,
    end_date::Date,
    market::Symbol
)
    
    parquet_dates = Date[]
    csv_dates = Date[]
    missing_dates = Date[]
    
    current_date = start_date
    while current_date <= end_date
        has_data, format = check_local_data_with_format(symbol, current_date, market)
        
        if has_data
            if format == PARQUET_FORMAT
                push!(parquet_dates, current_date)
            else
                push!(csv_dates, current_date)
            end
        else
            push!(missing_dates, current_date)
        end
        
        current_date += Day(1)
    end
    
    return (parquet_dates=parquet_dates, csv_dates=csv_dates, missing_dates=missing_dates)
end

# ============================================================================
# æ™ºèƒ½æ•°æ®è·å–ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
# ============================================================================

"""
    fetch_data(
        symbol::String,
        start_time::DateTime,
        end_time::DateTime;
        market::Symbol=:futures,
        use_cache::Bool=true,
        verbose::Bool=true
    )::DataFrame

æ™ºèƒ½è·å–æ•°æ®ï¼ˆä¼˜å…ˆçº§ï¼šæœ¬åœ° Parquet > æœ¬åœ° CSV > Vision > APIï¼‰
"""
function fetch_data(
    symbol::String,
    start_time::DateTime,
    end_time::DateTime;
    market::Symbol=:futures,
    use_cache::Bool=true,
    verbose::Bool=true
)::DataFrame
    
    if verbose
        println("\n" * "="^70)
        println("æ™ºèƒ½æ•°æ®è·å–")
        println("="^70)
        println("\né…ç½®:")
        println("  äº¤æ˜“å¯¹: $symbol")
        println("  æ—¶é—´èŒƒå›´: $start_time åˆ° $end_time")
        println("  å¸‚åœº: $market")
        println("  ä½¿ç”¨ç¼“å­˜: $use_cache")
    end
    
    # åˆ†å‰²æ—¶é—´èŒƒå›´
    vision_range, api_range = split_date_range(start_time, end_time)
    
    all_data = DataFrame[]
    
    # ========================================================================
    # ä¼˜å…ˆä»æœ¬åœ°åŠ è½½ï¼ˆParquet > CSVï¼‰
    # ========================================================================
    
    if !isnothing(vision_range)
        vision_start, vision_end = vision_range
        
        if verbose
            println("\nğŸ“¦ å†å²æ•°æ®èŒƒå›´ ($(vision_start) åˆ° $(vision_end)):")
        end
        
        # âœ… è¯¦ç»†æ£€æŸ¥æœ¬åœ°æ•°æ®ï¼ˆæŒ‰æ ¼å¼åˆ†ç±»ï¼‰
        coverage = get_local_coverage_detailed(symbol, vision_start, vision_end, market)
        
        total_days = Dates.value(vision_end - vision_start) + 1
        available_days = length(coverage.parquet_dates) + length(coverage.csv_dates)
        coverage_pct = available_days / total_days * 100
        
        if verbose
            if !isempty(coverage.parquet_dates)
                println("  âœ… Parquet æ–‡ä»¶: $(length(coverage.parquet_dates)) å¤©")
            end
            
            if !isempty(coverage.csv_dates)
                println("  ğŸ“„ CSV æ–‡ä»¶: $(length(coverage.csv_dates)) å¤© (å»ºè®®è½¬æ¢ä¸º Parquet)")
            end
            
            if !isempty(coverage.missing_dates)
                println("  ğŸ“¥ ç¼ºå¤±æ•°æ®: $(length(coverage.missing_dates)) å¤©")
            end
            
            println("  ğŸ“Š æœ¬åœ°è¦†ç›–ç‡: $(round(coverage_pct, digits=1))%")
        end
        
        # âœ… ä»æœ¬åœ°åŠ è½½å·²æœ‰æ•°æ®ï¼ˆè‡ªåŠ¨ä¼˜å…ˆ Parquetï¼‰
        local_data = DataFrame()
        if available_days > 0 && use_cache
            if verbose
                println("  ğŸ“‚ åŠ è½½æœ¬åœ°æ•°æ®...")
            end
            
            local_data = load_local_data_range(symbol, vision_start, vision_end, market)
            
            if verbose && nrow(local_data) > 0
                println("  âœ… å·²åŠ è½½: $(nrow(local_data)) ç¬”äº¤æ˜“")
            end
        end
        
        # âœ… ä¸‹è½½ç¼ºå¤±çš„æ•°æ®ï¼ˆä»…ç¼ºå¤±çš„æ—¥æœŸï¼‰
        if !isempty(coverage.missing_dates) && use_cache
            if verbose
                println("  ğŸ“¥ ä» Binance Vision ä¸‹è½½ $(length(coverage.missing_dates)) å¤©ç¼ºå¤±æ•°æ®...")
            end
            
            download_success = 0
            download_failed = 0
            
            for date in coverage.missing_dates
                try
                    # ä¸‹è½½å•å¤©æ•°æ®
                    day_data = download_date_range_aggtrades(
                        symbol,
                        date,
                        date,
                        market=market,
                        use_cache=false,  # Vision è‡ªå·±æœ‰ç¼“å­˜
                        merge=true
                    )
                    
                    # âœ… ä¿å­˜ä¸º Parquet æ ¼å¼
                    if nrow(day_data) > 0
                        save_local_data(day_data, symbol, date, market, PARQUET_FORMAT)
                        download_success += 1
                        
                        if verbose
                            println("    âœ… $date: $(nrow(day_data)) ç¬”äº¤æ˜“")
                        end
                    else
                        download_failed += 1
                        if verbose
                            println("    âš ï¸  $date: æ— æ•°æ®")
                        end
                    end
                    
                catch e
                    download_failed += 1
                    if verbose
                        println("    âŒ $date: ä¸‹è½½å¤±è´¥")
                    end
                end
            end
            
            if verbose && download_success > 0
                println("  âœ… Vision ä¸‹è½½å®Œæˆ: æˆåŠŸ $download_success å¤©, å¤±è´¥ $download_failed å¤©")
            end
            
            # é‡æ–°åŠ è½½æ‰€æœ‰æ•°æ®ï¼ˆåŒ…æ‹¬æ–°ä¸‹è½½çš„ï¼‰
            if download_success > 0
                local_data = load_local_data_range(symbol, vision_start, vision_end, market)
            end
        end
        
        # è¿‡æ»¤åˆ°ç²¾ç¡®æ—¶é—´
        if nrow(local_data) > 0
            mask = (local_data.timestamp .>= start_time) .& (local_data.timestamp .<= end_time)
            vision_data = local_data[mask, :]
            
            if nrow(vision_data) > 0
                push!(all_data, vision_data)
                
                if verbose
                    println("  âœ… å†å²æ•°æ®å·²å‡†å¤‡: $(nrow(vision_data)) ç¬”äº¤æ˜“")
                end
            end
        end
    end
    
    # ========================================================================
    # ä» API ä¸‹è½½ï¼ˆä»…åœ¨å¿…è¦æ—¶ï¼‰
    # ========================================================================
    
    if !isnothing(api_range)
        api_start, api_end = api_range
        
        if verbose
            println("\nğŸŒ æœ€æ–°æ•°æ® (Binance API):")
            println("  æ—¶é—´èŒƒå›´: $api_start åˆ° $api_end")
        end
        
        try
            api_data = fetch_aggtrades_from_api(
                symbol,
                api_start,
                api_end,
                market=market
            )
            
            if nrow(api_data) > 0
                push!(all_data, api_data)
                
                if verbose
                    println("  âœ… API æ•°æ®: $(nrow(api_data)) ç¬”äº¤æ˜“")
                end
                
                # âœ… ä¿å­˜ API æ•°æ®åˆ°æœ¬åœ°ï¼ˆParquet æ ¼å¼ï¼‰
                if use_cache && nrow(api_data) > 0
                    api_dates = unique(Date.(api_data.timestamp))
                    
                    if verbose
                        println("  ğŸ’¾ ä¿å­˜åˆ°æœ¬åœ° (Parquet æ ¼å¼)...")
                    end
                    
                    for date in api_dates
                        date_mask = Date.(api_data.timestamp) .== date
                        day_data = api_data[date_mask, :]
                        
                        if nrow(day_data) > 0
                            save_local_data(day_data, symbol, date, market, PARQUET_FORMAT)
                        end
                    end
                    
                    if verbose
                        println("  âœ… å·²ä¿å­˜ $(length(api_dates)) å¤©æ•°æ®")
                    end
                end
            else
                if verbose
                    println("  âš ï¸  API æ•°æ®ä¸å¯ç”¨")
                end
            end
            
        catch e
            if verbose
                println("  âŒ API ä¸‹è½½å¤±è´¥: $e")
            end
        end
    end
    
    # ========================================================================
    # åˆå¹¶æ•°æ®
    # ========================================================================
    
    if isempty(all_data)
        @warn "No data fetched for $symbol from $start_time to $end_time"
        return DataFrame(
            agg_trade_id = Int64[],
            price = Float64[],
            quantity = Float64[],
            first_trade_id = Int64[],
            last_trade_id = Int64[],
            timestamp = DateTime[],
            is_buyer_maker = Bool[],
            symbol = String[]
        )
    end
    
    result = vcat(all_data...)
    sort!(result, :timestamp)
    unique!(result, :agg_trade_id)
    
    if verbose
        println("\nğŸ“Š æ•°æ®æ±‡æ€»:")
        println("  æ€»æ•°æ®é‡: $(nrow(result)) ç¬”äº¤æ˜“")
        println("  æ—¶é—´èŒƒå›´: $(result[1, :timestamp]) åˆ° $(result[end, :timestamp])")
        println("  æ•°æ®å®Œæ•´æ€§: $(check_data_completeness(result, start_time, end_time))")
        println("="^70)
    end
    
    return result
end

# ============================================================================
# æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
# ============================================================================

"""
    check_data_completeness(df::DataFrame, start_time::DateTime, end_time::DateTime)::String

æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
"""
function check_data_completeness(df::DataFrame, start_time::DateTime, end_time::DateTime)::String
    
    if nrow(df) == 0
        return "âŒ æ— æ•°æ®"
    end
    
    actual_start = df[1, :timestamp]
    actual_end = df[end, :timestamp]
    
    # æ£€æŸ¥å¼€å§‹å’Œç»“æŸæ—¶é—´
    start_gap = Dates.value(actual_start - start_time) / 1000  # ç§’
    end_gap = Dates.value(end_time - actual_end) / 1000
    
    if start_gap > 60 || end_gap > 60  # è¶…è¿‡1åˆ†é’Ÿ
        missing_pct = ((start_gap + end_gap) / Dates.value(end_time - start_time) * 1000) * 100
        return "âš ï¸ ä¸å®Œæ•´ (ç¼ºå¤± $(round(missing_pct, digits=1))%)"
    end
    
    return "âœ… å®Œæ•´"
end

# ============================================================================
# å›æµ‹æ•°æ®å‡†å¤‡
# ============================================================================

"""
    fetch_data_for_backtest(
        symbol::String,
        start_time::DateTime,
        end_time::DateTime;
        market::Symbol=:futures,
        force_refresh::Bool=false
    )::DataFrame

ä¸ºå›æµ‹å‡†å¤‡æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
"""
function fetch_data_for_backtest(
    symbol::String,
    start_time::DateTime,
    end_time::DateTime;
    market::Symbol=:futures,
    force_refresh::Bool=false
)::DataFrame
    
    # ç”Ÿæˆç¼“å­˜æ–‡ä»¶å
    mkpath(BACKTEST_CACHE_DIR)
    
    start_str = Dates.format(start_time, "yyyymmdd_HHMMSS")
    end_str = Dates.format(end_time, "yyyymmdd_HHMMSS")
    cache_file = joinpath(
        BACKTEST_CACHE_DIR,
        "$(symbol)_$(market)_$(start_str)_$(end_str).csv"
    )
    
    # æ£€æŸ¥ç¼“å­˜
    if !force_refresh && isfile(cache_file)
        @info "Loading from cache" file=cache_file
        
        df = CSV.read(cache_file, DataFrame)
        
        # è½¬æ¢æ—¶é—´åˆ—
        if hasproperty(df, :timestamp) && eltype(df.timestamp) == String
            df.timestamp = DateTime.(df.timestamp)
        end
        
        @info "Loaded from cache" rows=nrow(df)
        return df
    end
    
    # ä¸‹è½½æ•°æ®
    @info "Fetching data for backtest" symbol=symbol start_time=start_time end_time=end_time
    
    df = fetch_data(
        symbol,
        start_time,
        end_time,
        market=market,
        use_cache=true,
        verbose=false
    )
    
    # ä¿å­˜åˆ°ç¼“å­˜
    if nrow(df) > 0
        CSV.write(cache_file, df)
        @info "Saved to cache" file=cache_file rows=nrow(df)
    end
    
    return df
end

# ============================================================================
# å¤šäº¤æ˜“å¯¹æ•°æ®å‡†å¤‡
# ============================================================================

"""
    prepare_multiple_symbols(
        symbols::Vector{String},
        start_time::DateTime,
        end_time::DateTime;
        market::Symbol=:futures
    )::Dict{String, DataFrame}

å‡†å¤‡å¤šä¸ªäº¤æ˜“å¯¹çš„æ•°æ®
"""
function prepare_multiple_symbols(
    symbols::Vector{String},
    start_time::DateTime,
    end_time::DateTime;
    market::Symbol=:futures
)::Dict{String, DataFrame}
    
    @info "Preparing multiple symbols" symbols=symbols count=length(symbols)
    
    result = Dict{String, DataFrame}()
    
    for symbol in symbols
        @info "Fetching $symbol..."
        
        try
            df = fetch_data_for_backtest(
                symbol,
                start_time,
                end_time,
                market=market
            )
            
            result[symbol] = df
            
            @info "Fetched $symbol" rows=nrow(df)
            
        catch e
            @error "Failed to fetch $symbol" error=e
            result[symbol] = DataFrame()
        end
    end
    
    return result
end

# ============================================================================
# ç¼“å­˜ç®¡ç†
# ============================================================================

"""
    clear_backtest_cache(;older_than_days::Int=7)

æ¸…ç†å›æµ‹ç¼“å­˜
"""
function clear_backtest_cache(;older_than_days::Int=7)
    
    if !isdir(BACKTEST_CACHE_DIR)
        @info "Cache directory does not exist"
        return
    end
    
    cutoff_time = now() - Day(older_than_days)
    deleted_count = 0
    freed_space = 0
    
    for file in readdir(BACKTEST_CACHE_DIR, join=true)
        if isfile(file)
            file_time = unix2datetime(stat(file).mtime)
            
            if file_time < cutoff_time
                file_size = stat(file).size
                rm(file)
                deleted_count += 1
                freed_space += file_size
                
                @debug "Deleted cache file" file=basename(file)
            end
        end
    end
    
    @info "Cache cleared" deleted_files=deleted_count freed_mb=round(freed_space/1024/1024, digits=2)
end

"""
    get_cache_info()

è·å–ç¼“å­˜ä¿¡æ¯
"""
function get_cache_info()
    
    if !isdir(BACKTEST_CACHE_DIR)
        println("å›æµ‹ç¼“å­˜ç›®å½•ä¸å­˜åœ¨")
        return
    end
    
    files = readdir(BACKTEST_CACHE_DIR, join=true)
    
    if isempty(files)
        println("å›æµ‹ç¼“å­˜ä¸ºç©º")
        return
    end
    
    println("\nå›æµ‹ç¼“å­˜ä¿¡æ¯:")
    println("  ç›®å½•: $BACKTEST_CACHE_DIR")
    println("  æ–‡ä»¶æ•°: $(length(files))")
    
    total_size = sum(stat(f).size for f in files)
    println("  æ€»å¤§å°: $(round(total_size/1024/1024, digits=2)) MB")
    
    println("\næœ€è¿‘çš„æ–‡ä»¶:")
    sorted_files = sort(files, by=f->stat(f).mtime, rev=true)
    
    for (i, file) in enumerate(first(sorted_files, 5))
        size_mb = round(stat(file).size / 1024 / 1024, digits=2)
        mtime = unix2datetime(stat(file).mtime)
        println("  $i. $(basename(file)) ($size_mb MB, $mtime)")
    end
end